MNIST->demo (w=30, split@11):   0%|          | 0/10 [00:00<?, ?it/s]sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
MNIST->demo (w=30, split@11):  10%|█         | 1/10 [06:00<54:05, 360.60s/it]MNIST->demo (w=30, split@11):  20%|██        | 2/10 [11:57<47:48, 358.57s/it]MNIST->demo (w=30, split@11):  30%|███       | 3/10 [17:54<41:43, 357.59s/it]MNIST->demo (w=30, split@11):  40%|████      | 4/10 [23:50<35:41, 356.91s/it]MNIST->demo (w=30, split@11):  50%|█████     | 5/10 [29:46<29:42, 356.57s/it]MNIST->demo (w=30, split@11):  60%|██████    | 6/10 [35:42<23:45, 356.38s/it]MNIST->demo (w=30, split@11):  70%|███████   | 7/10 [41:29<17:40, 353.60s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/anet/actions.py:70: UserWarning: OrthogonalDecomp sum check failed; falling back to half split.
  warnings.warn("OrthogonalDecomp sum check failed; falling back to half split.")
MNIST->demo (w=30, split@11):  80%|████████  | 8/10 [47:06<11:36, 348.03s/it]MNIST->demo (w=30, split@11):  90%|█████████ | 9/10 [52:41<05:44, 344.25s/it]MNIST->demo (w=30, split@11): 100%|██████████| 10/10 [58:18<00:00, 341.84s/it]MNIST->demo (w=30, split@11): 100%|██████████| 10/10 [58:18<00:00, 349.84s/it]
MNIST->demo (w=30, split@14):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@14):  10%|█         | 1/10 [05:13<47:03, 313.68s/it]MNIST->demo (w=30, split@14):  20%|██        | 2/10 [10:27<41:48, 313.51s/it]MNIST->demo (w=30, split@14):  30%|███       | 3/10 [15:40<36:33, 313.38s/it]MNIST->demo (w=30, split@14):  40%|████      | 4/10 [20:54<31:21, 313.57s/it]MNIST->demo (w=30, split@14):  50%|█████     | 5/10 [26:08<26:08, 313.73s/it]MNIST->demo (w=30, split@14):  60%|██████    | 6/10 [31:21<20:54, 313.70s/it]MNIST->demo (w=30, split@14):  70%|███████   | 7/10 [36:35<15:41, 313.71s/it]MNIST->demo (w=30, split@14):  80%|████████  | 8/10 [41:49<10:27, 313.68s/it]MNIST->demo (w=30, split@14):  90%|█████████ | 9/10 [47:03<05:13, 313.77s/it]MNIST->demo (w=30, split@14): 100%|██████████| 10/10 [52:17<00:00, 313.92s/it]MNIST->demo (w=30, split@14): 100%|██████████| 10/10 [52:17<00:00, 313.74s/it]
MNIST->demo (w=30, split@18):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@18):  10%|█         | 1/10 [04:43<42:28, 283.22s/it]MNIST->demo (w=30, split@18):  20%|██        | 2/10 [09:26<37:46, 283.29s/it]MNIST->demo (w=30, split@18):  30%|███       | 3/10 [14:09<33:02, 283.16s/it]MNIST->demo (w=30, split@18):  40%|████      | 4/10 [18:52<28:18, 283.07s/it]MNIST->demo (w=30, split@18):  50%|█████     | 5/10 [23:35<23:35, 283.02s/it]MNIST->demo (w=30, split@18):  60%|██████    | 6/10 [28:18<18:52, 283.05s/it]MNIST->demo (w=30, split@18):  70%|███████   | 7/10 [33:01<14:09, 283.09s/it]MNIST->demo (w=30, split@18):  80%|████████  | 8/10 [37:45<09:26, 283.16s/it]MNIST->demo (w=30, split@18):  90%|█████████ | 9/10 [42:28<04:43, 283.22s/it]MNIST->demo (w=30, split@18): 100%|██████████| 10/10 [47:12<00:00, 283.41s/it]MNIST->demo (w=30, split@18): 100%|██████████| 10/10 [47:12<00:00, 283.22s/it]
MNIST->demo (w=30, split@21):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@21):  10%|█         | 1/10 [04:20<39:03, 260.34s/it]MNIST->demo (w=30, split@21):  20%|██        | 2/10 [08:40<34:40, 260.08s/it]MNIST->demo (w=30, split@21):  30%|███       | 3/10 [13:00<30:20, 260.11s/it]MNIST->demo (w=30, split@21):  40%|████      | 4/10 [17:20<25:59, 259.99s/it]MNIST->demo (w=30, split@21):  50%|█████     | 5/10 [21:39<21:39, 259.84s/it]MNIST->demo (w=30, split@21):  60%|██████    | 6/10 [25:59<17:19, 259.93s/it]MNIST->demo (w=30, split@21):  70%|███████   | 7/10 [30:20<13:00, 260.04s/it]MNIST->demo (w=30, split@21):  80%|████████  | 8/10 [34:39<08:39, 259.97s/it]MNIST->demo (w=30, split@21):  90%|█████████ | 9/10 [38:59<04:19, 259.95s/it]MNIST->demo (w=30, split@21): 100%|██████████| 10/10 [43:19<00:00, 259.84s/it]MNIST->demo (w=30, split@21): 100%|██████████| 10/10 [43:19<00:00, 259.95s/it]
MNIST->demo (w=30, split@25):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@25):  10%|█         | 1/10 [03:48<34:20, 228.94s/it]MNIST->demo (w=30, split@25):  20%|██        | 2/10 [07:39<30:36, 229.62s/it]MNIST->demo (w=30, split@25):  30%|███       | 3/10 [11:28<26:47, 229.64s/it]MNIST->demo (w=30, split@25):  40%|████      | 4/10 [15:18<22:57, 229.53s/it]MNIST->demo (w=30, split@25):  50%|█████     | 5/10 [19:07<19:08, 229.60s/it]MNIST->demo (w=30, split@25):  60%|██████    | 6/10 [22:57<15:18, 229.63s/it]MNIST->demo (w=30, split@25):  70%|███████   | 7/10 [26:47<11:28, 229.63s/it]MNIST->demo (w=30, split@25):  80%|████████  | 8/10 [30:36<07:39, 229.58s/it]MNIST->demo (w=30, split@25):  90%|█████████ | 9/10 [34:25<03:49, 229.51s/it]MNIST->demo (w=30, split@25): 100%|██████████| 10/10 [38:15<00:00, 229.47s/it]MNIST->demo (w=30, split@25): 100%|██████████| 10/10 [38:15<00:00, 229.53s/it]
MNIST->demo (w=30, split@28):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@28):  10%|█         | 1/10 [03:26<30:55, 206.17s/it]MNIST->demo (w=30, split@28):  20%|██        | 2/10 [06:52<27:28, 206.12s/it]MNIST->demo (w=30, split@28):  30%|███       | 3/10 [10:18<24:02, 206.08s/it]MNIST->demo (w=30, split@28):  40%|████      | 4/10 [13:44<20:36, 206.13s/it]MNIST->demo (w=30, split@28):  50%|█████     | 5/10 [17:10<17:09, 205.99s/it]MNIST->demo (w=30, split@28):  60%|██████    | 6/10 [20:36<13:43, 205.95s/it]MNIST->demo (w=30, split@28):  70%|███████   | 7/10 [24:02<10:17, 205.95s/it]MNIST->demo (w=30, split@28):  80%|████████  | 8/10 [27:28<06:51, 205.96s/it]MNIST->demo (w=30, split@28):  90%|█████████ | 9/10 [30:53<03:25, 205.86s/it]MNIST->demo (w=30, split@28): 100%|██████████| 10/10 [34:19<00:00, 205.92s/it]MNIST->demo (w=30, split@28): 100%|██████████| 10/10 [34:19<00:00, 205.97s/it]
MNIST->demo (w=30, split@32):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@32):  10%|█         | 1/10 [02:55<26:15, 175.06s/it]MNIST->demo (w=30, split@32):  20%|██        | 2/10 [05:50<23:20, 175.12s/it]MNIST->demo (w=30, split@32):  30%|███       | 3/10 [08:45<20:26, 175.15s/it]MNIST->demo (w=30, split@32):  40%|████      | 4/10 [11:40<17:30, 175.09s/it]MNIST->demo (w=30, split@32):  50%|█████     | 5/10 [14:35<14:35, 175.08s/it]MNIST->demo (w=30, split@32):  60%|██████    | 6/10 [17:30<11:40, 175.09s/it]MNIST->demo (w=30, split@32):  70%|███████   | 7/10 [20:25<08:45, 175.10s/it]MNIST->demo (w=30, split@32):  80%|████████  | 8/10 [23:20<05:50, 175.15s/it]MNIST->demo (w=30, split@32):  90%|█████████ | 9/10 [26:15<02:55, 175.08s/it]MNIST->demo (w=30, split@32): 100%|██████████| 10/10 [29:11<00:00, 175.14s/it]MNIST->demo (w=30, split@32): 100%|██████████| 10/10 [29:11<00:00, 175.12s/it]
MNIST->demo (w=30, split@35):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@35):  10%|█         | 1/10 [02:32<22:49, 152.14s/it]MNIST->demo (w=30, split@35):  20%|██        | 2/10 [05:04<20:18, 152.28s/it]MNIST->demo (w=30, split@35):  30%|███       | 3/10 [07:36<17:46, 152.36s/it]MNIST->demo (w=30, split@35):  40%|████      | 4/10 [10:09<15:13, 152.28s/it]MNIST->demo (w=30, split@35):  50%|█████     | 5/10 [12:41<12:41, 152.31s/it]MNIST->demo (w=30, split@35):  60%|██████    | 6/10 [15:14<10:09, 152.38s/it]MNIST->demo (w=30, split@35):  70%|███████   | 7/10 [17:46<07:37, 152.54s/it]MNIST->demo (w=30, split@35):  80%|████████  | 8/10 [20:19<05:05, 152.62s/it]MNIST->demo (w=30, split@35):  90%|█████████ | 9/10 [22:52<02:32, 152.70s/it]MNIST->demo (w=30, split@35): 100%|██████████| 10/10 [25:25<00:00, 152.73s/it]MNIST->demo (w=30, split@35): 100%|██████████| 10/10 [25:25<00:00, 152.54s/it]
MNIST->demo (w=30, split@39):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@39):  10%|█         | 1/10 [02:02<18:18, 122.00s/it]MNIST->demo (w=30, split@39):  20%|██        | 2/10 [04:03<16:14, 121.87s/it]MNIST->demo (w=30, split@39):  30%|███       | 3/10 [06:05<14:13, 121.88s/it]MNIST->demo (w=30, split@39):  40%|████      | 4/10 [08:07<12:11, 121.87s/it]MNIST->demo (w=30, split@39):  50%|█████     | 5/10 [10:09<10:09, 121.96s/it]MNIST->demo (w=30, split@39):  60%|██████    | 6/10 [12:11<08:07, 121.94s/it]MNIST->demo (w=30, split@39):  70%|███████   | 7/10 [14:13<06:05, 121.81s/it]MNIST->demo (w=30, split@39):  80%|████████  | 8/10 [16:14<04:03, 121.72s/it]MNIST->demo (w=30, split@39):  90%|█████████ | 9/10 [18:15<02:01, 121.59s/it]MNIST->demo (w=30, split@39): 100%|██████████| 10/10 [20:17<00:00, 121.50s/it]MNIST->demo (w=30, split@39): 100%|██████████| 10/10 [20:17<00:00, 121.72s/it]
MNIST->demo (w=30, split@42):   0%|          | 0/10 [00:00<?, ?it/s]MNIST->demo (w=30, split@42):  10%|█         | 1/10 [01:38<14:43, 98.14s/it]MNIST->demo (w=30, split@42):  20%|██        | 2/10 [03:16<13:05, 98.15s/it]MNIST->demo (w=30, split@42):  30%|███       | 3/10 [04:54<11:27, 98.20s/it]MNIST->demo (w=30, split@42):  40%|████      | 4/10 [06:32<09:49, 98.18s/it]MNIST->demo (w=30, split@42):  50%|█████     | 5/10 [08:10<08:10, 98.13s/it]MNIST->demo (w=30, split@42):  60%|██████    | 6/10 [09:48<06:32, 98.13s/it]MNIST->demo (w=30, split@42):  70%|███████   | 7/10 [11:27<04:54, 98.13s/it]MNIST->demo (w=30, split@42):  80%|████████  | 8/10 [13:05<03:16, 98.15s/it]MNIST->demo (w=30, split@42):  90%|█████████ | 9/10 [14:43<01:38, 98.18s/it]MNIST->demo (w=30, split@42): 100%|██████████| 10/10 [16:21<00:00, 98.19s/it]MNIST->demo (w=30, split@42): 100%|██████████| 10/10 [16:21<00:00, 98.17s/it]
baseline:   0%|          | 0/50 [00:00<?, ?it/s]sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
baseline:   2%|▏         | 1/50 [00:33<27:04, 33.16s/it]baseline:   4%|▍         | 2/50 [01:06<26:29, 33.12s/it]baseline:   6%|▌         | 3/50 [01:39<25:54, 33.07s/it]baseline:   8%|▊         | 4/50 [02:12<25:19, 33.03s/it]baseline:  10%|█         | 5/50 [02:45<24:45, 33.02s/it]baseline:  12%|█▏        | 6/50 [03:18<24:16, 33.10s/it]baseline:  14%|█▍        | 7/50 [03:50<23:31, 32.82s/it]baseline:  16%|█▌        | 8/50 [04:21<22:35, 32.27s/it]baseline:  18%|█▊        | 9/50 [04:52<21:48, 31.92s/it]baseline:  20%|██        | 10/50 [05:24<21:06, 31.66s/it]baseline:  22%|██▏       | 11/50 [05:55<20:28, 31.49s/it]baseline:  24%|██▍       | 12/50 [06:26<19:53, 31.41s/it]baseline:  26%|██▌       | 13/50 [06:57<19:19, 31.35s/it]baseline:  28%|██▊       | 14/50 [07:28<18:46, 31.28s/it]baseline:  30%|███       | 15/50 [07:59<18:13, 31.24s/it]baseline:  32%|███▏      | 16/50 [08:31<17:41, 31.22s/it]baseline:  34%|███▍      | 17/50 [09:02<17:09, 31.21s/it]baseline:  36%|███▌      | 18/50 [09:33<16:37, 31.17s/it]baseline:  38%|███▊      | 19/50 [10:04<16:05, 31.16s/it]baseline:  40%|████      | 20/50 [10:35<15:34, 31.15s/it]baseline:  42%|████▏     | 21/50 [11:06<15:03, 31.16s/it]baseline:  44%|████▍     | 22/50 [11:37<14:32, 31.15s/it]baseline:  46%|████▌     | 23/50 [12:09<14:01, 31.17s/it]baseline:  48%|████▊     | 24/50 [12:40<13:30, 31.17s/it]baseline:  50%|█████     | 25/50 [13:11<13:00, 31.24s/it]baseline:  52%|█████▏    | 26/50 [13:42<12:28, 31.21s/it]baseline:  54%|█████▍    | 27/50 [14:13<11:57, 31.18s/it]baseline:  56%|█████▌    | 28/50 [14:45<11:25, 31.16s/it]baseline:  58%|█████▊    | 29/50 [15:16<10:54, 31.16s/it]baseline:  60%|██████    | 30/50 [15:47<10:22, 31.15s/it]baseline:  62%|██████▏   | 31/50 [16:18<09:51, 31.14s/it]baseline:  64%|██████▍   | 32/50 [16:49<09:20, 31.14s/it]baseline:  66%|██████▌   | 33/50 [17:20<08:49, 31.13s/it]baseline:  68%|██████▊   | 34/50 [17:51<08:18, 31.13s/it]baseline:  70%|███████   | 35/50 [18:22<07:47, 31.14s/it]baseline:  72%|███████▏  | 36/50 [18:54<07:15, 31.14s/it]baseline:  74%|███████▍  | 37/50 [19:25<06:45, 31.16s/it]baseline:  76%|███████▌  | 38/50 [19:56<06:14, 31.17s/it]baseline:  78%|███████▊  | 39/50 [20:27<05:42, 31.16s/it]baseline:  80%|████████  | 40/50 [20:58<05:11, 31.13s/it]baseline:  82%|████████▏ | 41/50 [21:29<04:40, 31.12s/it]baseline:  84%|████████▍ | 42/50 [22:00<04:08, 31.12s/it]baseline:  86%|████████▌ | 43/50 [22:32<03:37, 31.13s/it]baseline:  88%|████████▊ | 44/50 [23:03<03:06, 31.13s/it]baseline:  90%|█████████ | 45/50 [23:34<02:35, 31.14s/it]baseline:  92%|█████████▏| 46/50 [24:05<02:04, 31.13s/it]baseline:  94%|█████████▍| 47/50 [24:36<01:33, 31.15s/it]baseline:  96%|█████████▌| 48/50 [25:07<01:02, 31.16s/it]baseline:  98%|█████████▊| 49/50 [25:38<00:31, 31.15s/it]baseline: 100%|██████████| 50/50 [26:09<00:00, 31.11s/it]baseline: 100%|██████████| 50/50 [26:09<00:00, 31.40s/it]
random:   0%|          | 0/50 [00:00<?, ?it/s]random:   2%|▏         | 1/50 [00:32<26:08, 32.01s/it]random:   4%|▍         | 2/50 [01:03<25:34, 31.97s/it]random:   6%|▌         | 3/50 [01:35<25:02, 31.96s/it]random:   8%|▊         | 4/50 [02:07<24:30, 31.98s/it]random:  10%|█         | 5/50 [02:39<23:58, 31.97s/it]random:  12%|█▏        | 6/50 [03:11<23:27, 31.99s/it]random:  14%|█▍        | 7/50 [03:43<22:55, 31.99s/it]random:  16%|█▌        | 8/50 [04:15<22:24, 32.01s/it]random:  18%|█▊        | 9/50 [04:47<21:51, 32.00s/it]random:  20%|██        | 10/50 [05:19<21:20, 32.00s/it]random:  22%|██▏       | 11/50 [05:51<20:48, 32.01s/it]random:  24%|██▍       | 12/50 [06:23<20:16, 32.01s/it]random:  26%|██▌       | 13/50 [06:55<19:44, 32.01s/it]random:  28%|██▊       | 14/50 [07:27<19:12, 32.01s/it]random:  30%|███       | 15/50 [07:59<18:40, 32.00s/it]random:  32%|███▏      | 16/50 [08:31<18:08, 32.00s/it]random:  34%|███▍      | 17/50 [09:03<17:35, 32.00s/it]random:  36%|███▌      | 18/50 [09:35<17:03, 32.00s/it]random:  38%|███▊      | 19/50 [10:07<16:31, 31.98s/it]random:  40%|████      | 20/50 [10:39<15:59, 31.99s/it]random:  42%|████▏     | 21/50 [11:11<15:27, 32.00s/it]random:  44%|████▍     | 22/50 [11:43<14:56, 32.02s/it]random:  46%|████▌     | 23/50 [12:16<14:24, 32.03s/it]random:  48%|████▊     | 24/50 [12:48<13:52, 32.02s/it]random:  50%|█████     | 25/50 [13:20<13:20, 32.00s/it]random:  52%|█████▏    | 26/50 [13:51<12:47, 32.00s/it]random:  54%|█████▍    | 27/50 [14:23<12:15, 31.99s/it]random:  56%|█████▌    | 28/50 [14:55<11:43, 31.99s/it]random:  58%|█████▊    | 29/50 [15:27<11:12, 32.00s/it]random:  60%|██████    | 30/50 [16:00<10:40, 32.02s/it]random:  62%|██████▏   | 31/50 [16:32<10:08, 32.02s/it]random:  64%|██████▍   | 32/50 [17:04<09:36, 32.00s/it]random:  66%|██████▌   | 33/50 [17:36<09:04, 32.03s/it]random:  68%|██████▊   | 34/50 [18:08<08:32, 32.03s/it]random:  70%|███████   | 35/50 [18:40<08:00, 32.04s/it]random:  72%|███████▏  | 36/50 [19:12<07:28, 32.02s/it]random:  74%|███████▍  | 37/50 [19:44<06:56, 32.02s/it]random:  76%|███████▌  | 38/50 [20:16<06:24, 32.02s/it]random:  78%|███████▊  | 39/50 [20:48<05:52, 32.02s/it]random:  80%|████████  | 40/50 [21:20<05:20, 32.02s/it]random:  82%|████████▏ | 41/50 [21:52<04:48, 32.01s/it]random:  84%|████████▍ | 42/50 [22:24<04:16, 32.01s/it]random:  86%|████████▌ | 43/50 [22:56<03:43, 31.99s/it]random:  88%|████████▊ | 44/50 [23:28<03:11, 31.99s/it]random:  90%|█████████ | 45/50 [24:00<02:39, 32.00s/it]random:  92%|█████████▏| 46/50 [24:32<02:08, 32.01s/it]random:  94%|█████████▍| 47/50 [25:04<01:36, 32.00s/it]random:  96%|█████████▌| 48/50 [25:36<01:03, 31.99s/it]random:  98%|█████████▊| 49/50 [26:08<00:32, 32.00s/it]random: 100%|██████████| 50/50 [26:40<00:00, 32.01s/it]random: 100%|██████████| 50/50 [26:40<00:00, 32.01s/it]
greedy:   0%|          | 0/50 [00:00<?, ?it/s]sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:   2%|▏         | 1/50 [00:32<26:21, 32.27s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:   4%|▍         | 2/50 [01:04<25:52, 32.35s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:   6%|▌         | 3/50 [01:37<25:21, 32.37s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:   8%|▊         | 4/50 [02:09<24:48, 32.36s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  10%|█         | 5/50 [02:41<24:15, 32.35s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  12%|█▏        | 6/50 [03:14<23:42, 32.32s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  14%|█▍        | 7/50 [03:46<23:09, 32.31s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  16%|█▌        | 8/50 [04:18<22:38, 32.34s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  18%|█▊        | 9/50 [04:51<22:06, 32.36s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  20%|██        | 10/50 [05:23<21:34, 32.35s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  22%|██▏       | 11/50 [05:55<21:01, 32.34s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  24%|██▍       | 12/50 [06:28<20:28, 32.34s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  26%|██▌       | 13/50 [07:00<19:56, 32.35s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  28%|██▊       | 14/50 [07:32<19:24, 32.36s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  30%|███       | 15/50 [08:05<18:53, 32.39s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  32%|███▏      | 16/50 [08:37<18:20, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  34%|███▍      | 17/50 [09:10<17:48, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  36%|███▌      | 18/50 [09:42<17:16, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  38%|███▊      | 19/50 [10:14<16:44, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  40%|████      | 20/50 [10:47<16:11, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  42%|████▏     | 21/50 [11:19<15:38, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  44%|████▍     | 22/50 [11:51<15:06, 32.37s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  46%|████▌     | 23/50 [12:24<14:33, 32.37s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  48%|████▊     | 24/50 [12:56<14:01, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  50%|█████     | 25/50 [13:29<13:29, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  52%|█████▏    | 26/50 [14:01<12:56, 32.37s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  54%|█████▍    | 27/50 [14:33<12:24, 32.35s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  56%|█████▌    | 28/50 [15:06<11:51, 32.36s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  58%|█████▊    | 29/50 [15:38<11:19, 32.36s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  60%|██████    | 30/50 [16:10<10:47, 32.37s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  62%|██████▏   | 31/50 [16:43<10:15, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  64%|██████▍   | 32/50 [17:15<09:43, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  66%|██████▌   | 33/50 [17:48<09:10, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  68%|██████▊   | 34/50 [18:20<08:38, 32.38s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  70%|███████   | 35/50 [18:52<08:06, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  72%|███████▏  | 36/50 [19:25<07:33, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  74%|███████▍  | 37/50 [19:57<07:01, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  76%|███████▌  | 38/50 [20:30<06:28, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  78%|███████▊  | 39/50 [21:02<05:56, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  80%|████████  | 40/50 [21:34<05:24, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  82%|████████▏ | 41/50 [22:07<04:51, 32.39s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  84%|████████▍ | 42/50 [22:39<04:19, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  86%|████████▌ | 43/50 [23:12<03:46, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  88%|████████▊ | 44/50 [23:44<03:14, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  90%|█████████ | 45/50 [24:16<02:41, 32.40s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  92%|█████████▏| 46/50 [24:49<02:09, 32.41s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  94%|█████████▍| 47/50 [25:21<01:37, 32.43s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  96%|█████████▌| 48/50 [25:54<01:04, 32.44s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy:  98%|█████████▊| 49/50 [26:26<00:32, 32.43s/it]/project/caai_amzn_cmpr/efithian/Adaptive-Net/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
greedy: 100%|██████████| 50/50 [26:59<00:00, 32.43s/it]greedy: 100%|██████████| 50/50 [26:59<00:00, 32.38s/it]
